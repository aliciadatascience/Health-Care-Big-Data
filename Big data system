In order to deal with big data set and implement your algorithm to process big dataset, we need big data systems.

Hadoop: distributed disk-based big data system
Spark: distributed in-memory big data system

Generally, spark is much faster than Hadoop.

Building blocks of Hadoop:
    core infrastructure of Hadoop
    MapReduce programming model
    HDFS storage system
    High-level processing system: Hive, Pig etc.

Building blocks of Spark:
    Spark SQL
    Spark Streaming（实时处理）
    MLlib for large scale ML library using Spark(algorithms that Spark support):
        1). Classification: logistic regression, linear support vector machine, naive bayes, classification tree
        2). regression: generalized linear model, regression tree
        3). collaborative filtering: alternating least squares(ALS)
        4). clustering: k-means
        5). Decomposition: singular value decomposition(SVD), PCA
        
    GraphX for processing graph data using Spark
    
    
    
